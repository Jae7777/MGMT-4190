{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b59098-acc3-42b3-8627-af129bc2e60b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e87befa6d147437c24c981230c9ddee",
     "grade": false,
     "grade_id": "Instructions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Assignment-3\n",
    "##### Total number of points: 50\n",
    "#### Due date: 10/7/2024 11:59 PM\n",
    "\n",
    "Before you submit this homework, make sure everything runs as expected. First, restart the kernel (in the menu, select Kernel → Restart) and then run all cells (in the menubar, select Cell → Run All). You can discuss with others regarding the homework but all work must be your own.\n",
    "\n",
    "Steps to evaluate your solutions:\n",
    "\n",
    "Step-1: Try on Colab or Anaconda (Windows: https://docs.anaconda.com/anaconda/install/windows/ ; Mac:https://docs.anaconda.com/anaconda/install/mac-os/ ; Linux: https://docs.anaconda.com/anaconda/install/linux/)\n",
    "\n",
    "Step-2: Open the Jupyter Notebook by first launching the anaconda software console\n",
    "\n",
    "Step-3: Open the homework's .ipynb file and write your solutions at the appropriate location \"# YOUR CODE HERE\"\n",
    "\n",
    "Step-4: You can restart the kernel and click run all (in the menubar, select Cell → Run All) on the center-right on the top of this window.\n",
    "\n",
    "Step-5: Now go to \"File\" then click on \"Download as\" then click on \"Notebook (.ipynb)\" Please DO NOT change the file name and just keep it as \".ipynb\"\n",
    "\n",
    "Step-6: Go to lms.rpi.edu and upload your homework at the appropriate link to submit this homework.\n",
    "\n",
    "\n",
    "#### Please note that for any question in this assignment you will receive points ONLY if your solution passes all the test cases including hidden testcases as well. So please make sure you try to think all possible scenarios before submitting your answers.  \n",
    "- Note that hidden tests are present to ensure you are not hardcoding.\n",
    "- Failure to use proper letter casing for variable names will lead to loss of points. \n",
    "- If caught cheating: \n",
    "    - you will receive a score of 0 for the 1st violation. \n",
    "    - for repeated incidents, you will receive an automatic 'F' grade and will be reported to the dean of Lally School of Management.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634e94ba-dca4-4e90-b393-7ecd4d99799c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5e88800bfaf73abf992af4d399bfe93",
     "grade": false,
     "grade_id": "Data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### We will be using the popular breast cancer wisconsin dataset for this homework (more details here: [url](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab91eddc-77ee-4178-b80f-ca658385b930",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae25f2a4f1929080b9502310fac4317e",
     "grade": false,
     "grade_id": "Q1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q1. Metadata and building the feature set and target variable. \n",
    "1. Load the data separately as `X` and `y_true` corresponding to features and class label or target variable respectively using the `load_breast_cancer()` function. When you build the feature set `X` make sure `X` is a numpy's ndarray. More details about `load_breast_cancer()` function can be found here in the Examples section: [url](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)  <br>\n",
    "\n",
    "2. Save all the `feature names` as a list of strings named as `colnames`.<br>\n",
    "\n",
    "3. Convert `X` from numpy ndarray to a pandas dataframe (name this as `df_X`) that contains both data and the corresponding feature names.<br>\n",
    "\n",
    "4. Perform standardization on all the features in `df_X` and save the standardized data as a dataframe named `df_X_std`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3b3de2-cea6-45ac-a9ee-1cdf1f0d1559",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dddf3131c0c4fd666774e517e63f314b",
     "grade": false,
     "grade_id": "Q1-Sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import math\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y_true = data.target\n",
    "colnames = data.feature_names\n",
    "df_X = pd.DataFrame(X, columns=colnames)\n",
    "df_X_std = df_X.std()\n",
    "# print(df_X_std)\n",
    "print(y_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d089987e-5cdd-4041-b68c-458f0f6d3d4c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "126dcc773f959f030addd2b12c460528",
     "grade": true,
     "grade_id": "1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-1 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL\n",
    "assert isinstance(X,np.ndarray)==True\n",
    "assert isinstance(y_true,np.ndarray)==True\n",
    "assert len(X)==569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbded6a-de8a-407d-afb6-3b34a34a9d53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c818d7702eb5a077be3c6c3ae583e7ae",
     "grade": true,
     "grade_id": "2",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-2 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL\n",
    "assert sum(y_true)==357\n",
    "assert df_X.isnull().values.sum()==0\n",
    "assert len(set(colnames))==30\n",
    "assert 'symmetry error' in colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ac71671-6887-4712-9ed0-3f7b53fc79ba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b774040530526e81591a6a257a3195c",
     "grade": true,
     "grade_id": "3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-3 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c77e22a-ad9f-4c6b-8182-189efc3d5083",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c38e0e5b699a1d1b79b989dd3a9d2f42",
     "grade": false,
     "grade_id": "Q2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q2. Sampling with replacement\n",
    "1. Create a new dataframe `ndf` using `df_X` from the previous question by randomly sampling the data points with replacement. Sample size is 400. \n",
    "\n",
    "Please note that we are not doing sampling without replacement here which means, there is a possibility of repeated datapoints in `ndf`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "925d87b0-e312-4244-86fa-3b79f0036bdb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6123ad88c81f09ddede106efe919ff0",
     "grade": false,
     "grade_id": "Q2-Sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "529       12.070         13.44           77.83      445.2          0.11000   \n",
      "438       13.850         19.60           88.68      592.6          0.08684   \n",
      "459        9.755         28.20           61.68      290.9          0.07984   \n",
      "136       11.710         16.67           74.72      423.6          0.10510   \n",
      "545       13.620         23.23           87.19      573.2          0.09246   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "3         11.420         20.38           77.58      386.1          0.14250   \n",
      "363       16.500         18.29          106.60      838.1          0.09686   \n",
      "292       12.950         16.02           83.14      513.7          0.10050   \n",
      "341        9.606         16.84           61.64      280.5          0.08481   \n",
      "141       16.110         18.05          105.10      813.0          0.09721   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "529           0.09009         0.03781              0.02798         0.1657   \n",
      "438           0.06330         0.01342              0.02293         0.1555   \n",
      "459           0.04626         0.01541              0.01043         0.1621   \n",
      "136           0.06095         0.03592              0.02600         0.1339   \n",
      "545           0.06747         0.02974              0.02443         0.1664   \n",
      "..                ...             ...                  ...            ...   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "363           0.08468         0.05862              0.04835         0.1495   \n",
      "292           0.07943         0.06155              0.03370         0.1730   \n",
      "341           0.09228         0.08422              0.02292         0.2036   \n",
      "141           0.11370         0.09447              0.05943         0.1861   \n",
      "\n",
      "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
      "529                 0.06608  ...         13.45          15.77   \n",
      "438                 0.05673  ...         15.63          28.01   \n",
      "459                 0.05952  ...         10.67          36.92   \n",
      "136                 0.05945  ...         13.33          25.48   \n",
      "545                 0.05801  ...         15.35          29.09   \n",
      "..                      ...  ...           ...            ...   \n",
      "3                   0.09744  ...         14.91          26.50   \n",
      "363                 0.05593  ...         18.13          25.45   \n",
      "292                 0.06470  ...         13.74          19.93   \n",
      "341                 0.07125  ...         10.75          23.07   \n",
      "141                 0.06248  ...         19.92          25.27   \n",
      "\n",
      "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
      "529            86.92       549.9            0.1521             0.1632   \n",
      "438           100.90       749.1            0.1118             0.1141   \n",
      "459            68.03       349.9            0.1110             0.1109   \n",
      "136            86.16       546.7            0.1271             0.1028   \n",
      "545            97.58       729.8            0.1216             0.1517   \n",
      "..               ...         ...               ...                ...   \n",
      "3              98.87       567.7            0.2098             0.8663   \n",
      "363           117.20      1009.0            0.1338             0.1679   \n",
      "292            88.81       585.4            0.1483             0.2068   \n",
      "341            71.25       353.6            0.1233             0.3416   \n",
      "141           129.00      1233.0            0.1314             0.2236   \n",
      "\n",
      "     worst concavity  worst concave points  worst symmetry  \\\n",
      "529          0.16220               0.07393          0.2781   \n",
      "438          0.04753               0.05890          0.2513   \n",
      "459          0.07190               0.04866          0.2321   \n",
      "136          0.10460               0.06968          0.1712   \n",
      "545          0.10490               0.07174          0.2642   \n",
      "..               ...                   ...             ...   \n",
      "3            0.68690               0.25750          0.6638   \n",
      "363          0.16630               0.09123          0.2394   \n",
      "292          0.22410               0.10560          0.3380   \n",
      "341          0.43410               0.08120          0.2982   \n",
      "141          0.28020               0.12160          0.2792   \n",
      "\n",
      "     worst fractal dimension  \n",
      "529                  0.08052  \n",
      "438                  0.06911  \n",
      "459                  0.07211  \n",
      "136                  0.07343  \n",
      "545                  0.06953  \n",
      "..                       ...  \n",
      "3                    0.17300  \n",
      "363                  0.06469  \n",
      "292                  0.09584  \n",
      "341                  0.09825  \n",
      "141                  0.08158  \n",
      "\n",
      "[400 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a new dataframe ndf \n",
    "# YOUR CODE HERE\n",
    "ndf = df_X.sample(n=400, replace=True)\n",
    "print(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f69495d-c173-4cf8-9f41-35516ff21bf9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "778910a25e0c056786e8cd6de63fe219",
     "grade": true,
     "grade_id": "4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-4 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c9894e-a046-4860-832f-57bf70a7dbe0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63e8399f31027fbabb8398872dd1eb7c",
     "grade": false,
     "grade_id": "Q3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3. Robustness metrics. \n",
    "1. Lets focus on the target variable or the class label column `y_true`. \n",
    "2. Create two lists `y_pred` and `y_pred_prob` which are of the same length as `y_true`.\n",
    "    - assume that `y_pred` is the list of predicted class labels from the classifier.\n",
    "    - `y_pred_prob` is the list of class probabilities from the classifier.\n",
    "    - Assume that all the values in `y_pred` are `1`s and `y_pred_prob` are all `0.4` which is a vector of probability estimates.\n",
    "3. Use the predicted class labels `y_pred` to compute precision, recall, accuracy values and save them as `precision`, `recall`, and `accuracy` respectively.\n",
    "4. Also compute the area under curve and save it as variable name `auc_score`.\n",
    "\n",
    "Please make sure you have all the variables assigned with the values and use the same letter casing as used here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4e0bde7-1474-435c-9980-83e46af1cc5b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97f2f63f0054d041bd3d79201d1db9e9",
     "grade": false,
     "grade_id": "Q3-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Create y_pred and y_pred_prob\n",
    "y_pred = [1] * len(y_true)\n",
    "y_pred_prob = [0.4] * len(y_true)\n",
    "\n",
    "# Compute precision, recall, and accuracy\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Compute area under curve\n",
    "auc_score = roc_auc_score(y_true, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9454ad00-fb13-4d4f-964f-444cdf2e0bf9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "230394a8e2eb21c2c31af6a5cd7b6b7d",
     "grade": true,
     "grade_id": "5",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-5 (10 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL\n",
    "assert round(precision,2) == 0.63\n",
    "assert round(recall,2) == 1.0\n",
    "assert round(accuracy,2) == 0.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c7848b7-0ee6-4698-9678-777b8f19cb87",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8532d98816f7bdcdb31c75fa500af263",
     "grade": true,
     "grade_id": "6",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-6 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d13aa-c77b-4a42-a444-f6c7813195e5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9ee3c20adc272a3278f1084da861b28",
     "grade": false,
     "grade_id": "Q4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q4. Data preprocessing and dimensionality reduction using PCA. \n",
    "\n",
    "1. Consider the same dataset ([url](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)) to create `X` and `y` where, `X` corresponds to only the feature columns, and `y` corresponds to the class label column `y_true`. Please make sure you check the casing -- `X` and `y` are in uppercase and lowercase formats respectively. <br><br>\n",
    "\n",
    "2. Standardize all the features (`X`) using StandardScaler function and save its output as `X_std`. <br><br>\n",
    "\n",
    "3. Consider only the top-`k` Principal components that that will retain not more than 90% of the information present in the original dataset. In other words just choose the first `k` principal components that capture 90% of variance only. Please assign the integer variable `k` with the total number of these top principal components. <br><br>\n",
    "\n",
    "4. Translate the data only into those `k` new feature (which are the principal components) space and save the transformed data as `X_pca`. <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11e9cab0-f2f4-4346-ac37-b806c56588b3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "001d8a957d52d70d9593ddf2e3153b1b",
     "grade": false,
     "grade_id": "Q4-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "#Perform standardization using StandardScaler function and perform PCA.\n",
    "\n",
    "#Consider only the top-k Principal components that that will retain not more than 78% of the information present in the original dataset.\n",
    "\n",
    "#In other words just choose the first k principal components that capture 78% of variance only.\n",
    "\n",
    "#How many such PCs should be considered?\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "# Perform PCA to retain 90% of the variance\n",
    "pca = PCA(n_components=6)\n",
    "X_pca = pca.fit_transform(X_std)\n",
    "\n",
    "# Number of principal components\n",
    "k = X_pca.shape[1]\n",
    "print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "356f4f23-c762-453e-a4a8-411ce3850713",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7716b21c29f0edb0f206be31ad389ba",
     "grade": true,
     "grade_id": "7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-7 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL\n",
    "assert len(X)==569\n",
    "assert len(X[0])==30\n",
    "assert len(X)==len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "681ffa51-1886-466f-ad0f-271d097f5792",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62d38a501324197e0b1ec6dd0dbd6f4c",
     "grade": true,
     "grade_id": "8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-8 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL\n",
    "assert round(np.mean(X_std),2)==0\n",
    "assert round(np.std(X_std),2)==1\n",
    "assert len(X_pca)==len(X)\n",
    "assert k>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e01a771-379f-42df-8b27-9c424e1e08b6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bdcb33b7eb5be62ece9c54bc80ebfa2",
     "grade": true,
     "grade_id": "9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-9 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MGMT-4190",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
