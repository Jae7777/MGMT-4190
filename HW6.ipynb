{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "946072c5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c8fdbc649c1e52f09f0b0816fe343e80",
     "grade": false,
     "grade_id": "Instructions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Assignment-6\n",
    "##### Total number of points: 40\n",
    "#### Due date: 11/14/2024 11:59 PM\n",
    "\n",
    "Before you submit this homework, make sure everything runs as expected. First, restart the kernel (in the menu, select Kernel → Restart) and then run all cells (in the menubar, select Cell → Run All). You can discuss with others regarding the homework but all work must be your own.\n",
    "\n",
    "Steps to evaluate your solutions:\n",
    "\n",
    "Step-1: Try on Colab or Anaconda (Windows: https://docs.anaconda.com/anaconda/install/windows/ ; Mac:https://docs.anaconda.com/anaconda/install/mac-os/ ; Linux: https://docs.anaconda.com/anaconda/install/linux/)\n",
    "\n",
    "Step-2: Open the Jupyter Notebook by first launching the anaconda software console\n",
    "\n",
    "Step-3: Open the homework's .ipynb file and write your solutions at the appropriate location \"# YOUR CODE HERE\"\n",
    "\n",
    "Step-4: You can restart the kernel and click run all (in the menubar, select Cell → Run All) on the center-right on the top of this window.\n",
    "\n",
    "Step-5: Now go to \"File\" then click on \"Download as\" then click on \"Notebook (.ipynb)\" Please DO NOT change the file name and just keep it as \".ipynb\"\n",
    "\n",
    "Step-6: Go to lms.rpi.edu and upload your homework at the appropriate link to submit this homework.\n",
    "\n",
    "\n",
    "#### Please note that for any question in this assignment you will receive points ONLY if your solution passes all the test cases including hidden testcases as well. So please make sure you try to think all possible scenarios before submitting your answers.  \n",
    "- Note that hidden tests are present to ensure you are not hardcoding.\n",
    "- Failure to use proper letter casing for variable names will lead to loss of points. \n",
    "- If caught cheating: \n",
    "    - you will receive a score of 0 for the 1st violation. \n",
    "    - for repeated incidents, you will receive an automatic 'F' grade and will be reported to the dean of Lally School of Management.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef6f8f6a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ebca1ca0828d19a57584877d342cfc79",
     "grade": false,
     "grade_id": "cell-92f5478d5bf05f89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Page total likes', 'Type', 'Category', 'Post Month', 'Post Weekday',\n",
       "       'Post Hour', 'Paid', 'Lifetime Post Total Reach',\n",
       "       'Lifetime Post Total Impressions', 'Lifetime Engaged Users',\n",
       "       'Lifetime Post Consumers', 'Lifetime Post Consumptions',\n",
       "       'Lifetime Post Impressions by people who have liked your Page',\n",
       "       'Lifetime Post reach by people who like your Page',\n",
       "       'Lifetime People who have liked your Page and engaged with your post',\n",
       "       'comment', 'like', 'share', 'Total Interactions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Please run this cell to load the dataset. \n",
    "url = 'https://raw.githubusercontent.com/lmanikon/lmanikon.github.io/master/teaching/datasets/dataset_Facebook.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "df  = pd.read_csv(url)\n",
    "df = df.dropna()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340c66d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e16141c395aa1206025f448b922a0af6",
     "grade": false,
     "grade_id": "q1-desc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Part-1 [24 points]: We will leverage randomforest classifier to identify the best features that predict 'Total Interactions'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87435723",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb2499c613df11ffaef3f372f01f59be",
     "grade": false,
     "grade_id": "q1-question",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1. Create a new dataframe `df_sub2` that contains only these feature columns in `df` : \n",
    "- `Page total likes`, `Type`, `Category`, `Post Month`, `Post Weekday`, `Post Hour`, `Paid`,  `Total Interactions`\n",
    "\n",
    "#### 2. Transform the categorical attribute `Type` in `df_sub2` to numerical attribute this way: \n",
    "- `Link`:1, `Photo`:2, `Status`:3, `Video`:4\n",
    "\n",
    "#### 3. Perform Standardization (using the formula we learnt) only on `Page total likes` column in `df_sub2` \n",
    "- Please use `<dataframe>.mean()` `<dataframe>.std()` if you are using the mean and std values to manipulate the column. \n",
    "    \n",
    "#### 4. Using `df_sub2` perform train_test_split operation to build training (`X_train`, `y_train`) and testing data (`X_test`, `y_test`).\n",
    "- Use test_size=0.3, random_state=42 as the parameters for train_test_split() function. \n",
    "- Feature columns (X): `Page total likes`, `Type`, `Category`, `Post Month`, `Post Weekday`, `Post Hour`, `Paid`\n",
    "- CLass label column (y): `Total Interactions`\n",
    "\n",
    "#### 5. Train the randomforest classifier (initialized as variable `rf`) using these parameters: max_depth=3, random_state=0. \n",
    "- Using the trained model `rf` compute the impurity-based feature importances.\n",
    "- Append the names of these top-3 features to list `impFeatures`. Please make sure you type the feature names exactly as in df_sub2 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f5cb344",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b63439fc717acf176c5fe45dc78b5cdf",
     "grade": false,
     "grade_id": "q1-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_11884\\1820953736.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sub2['Type'] = df_sub2['Type'].map({'Link': 1, 'Photo': 2, 'Status': 3, 'Video': 4})\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_11884\\1820953736.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sub2['Page total likes'] = (df_sub2['Page total likes'] - df_sub2['Page total likes'].mean()) / df_sub2['Page total likes'].std()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# 1\n",
    "df_sub2 = df[['Page total likes', 'Type', 'Category', 'Post Month', 'Post Weekday', 'Post Hour', 'Paid', 'Total Interactions']]\n",
    "\n",
    "# 2\n",
    "df_sub2['Type'] = df_sub2['Type'].map({'Link': 1, 'Photo': 2, 'Status': 3, 'Video': 4})\n",
    "\n",
    "# 3\n",
    "df_sub2['Page total likes'] = (df_sub2['Page total likes'] - df_sub2['Page total likes'].mean()) / df_sub2['Page total likes'].std()\n",
    "\n",
    "# 4\n",
    "X = df_sub2[['Page total likes', 'Type', 'Category', 'Post Month', 'Post Weekday', 'Post Hour', 'Paid']]\n",
    "y = df_sub2['Total Interactions']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 5\n",
    "rf = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[-3:][::-1]\n",
    "impFeatures = [X.columns[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8734682-f4cd-4c5f-a353-f0ee0eebc8e1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f32ec14a16250f22d204415b997ba862",
     "grade": true,
     "grade_id": "t1",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#check for variable names\n",
    "assert 'df_sub2' in globals()\n",
    "assert 'X_train' in globals()\n",
    "assert 'impFeatures' in globals()\n",
    "assert 'rf' in globals()\n",
    "assert 'y_test' in globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae1042a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfbbbfeabb4913c4267e448a55c065c1",
     "grade": true,
     "grade_id": "1",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-1 (6 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL\n",
    "assert set(df_sub2.columns)=={'Post Hour', 'Total Interactions', 'Post Weekday', 'Category', 'Paid', 'Post Month', 'Page total likes', 'Type'}\n",
    "assert len(df_sub2)==495\n",
    "assert len(df_sub2.iloc[0,:])==8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a9e25ec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75b8a4ce34a18bad62197f4c75643850",
     "grade": true,
     "grade_id": "2",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-2 (6 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL\n",
    "assert math.ceil(df_sub2['Page total likes'].mean())==1\n",
    "assert len(X_train)==346\n",
    "assert 'Post Hour' in impFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bbd8fe4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca0bdbb308d1890d3475effa50568c97",
     "grade": true,
     "grade_id": "3",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-3 (6 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL\n",
    "assert rf.n_classes_==230\n",
    "assert len(impFeatures)==3\n",
    "assert math.ceil(df_sub2['Page total likes'].std())==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53163b00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "024bdb0f63bb2ecc7e27fe5229ce1d5a",
     "grade": true,
     "grade_id": "4",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-4 (6 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba946a55",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d09d7bc876c586b13bf44875d4499463",
     "grade": false,
     "grade_id": "q2-desc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Part-2 [16 points]: We will now use neural networks to model a regression problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8ec561",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cead998a4ee6548b00b2213231b77652",
     "grade": false,
     "grade_id": "q2-question",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1. Create a new dataframe `df_sub4` that contains only these feature columns in `df` : \n",
    "- `Page total likes`, `Type`, `Category`, `Post Month`, `Post Weekday`, `Post Hour`, `Paid`,  `Total Interactions`\n",
    "\n",
    "#### 2. Perform one-hot encoding on these features below in the dataframe `df_sub4` to create a new dataframe `df_OHE`\n",
    "- `Type`, `Category`, `Post Month`, `Post Weekday`, `Post Hour`\n",
    "\n",
    "#### 3. Perform normalization only on `Page total likes` and `Total Interactions` column in `df_OHE` using MinMaxScaler or minmax_scale \n",
    "- note that both these functions will output the same result\n",
    "\n",
    "#### 4. Using `df_OHE` perform train_test_split operation to build training (`X_train`, `y_train`) and testing data (`X_test`, `y_test`).\n",
    "- Use test_size=0.3, random_state=42 as the parameters for train_test_split() function. \n",
    "- Feature columns (X): Everything except `Total Interactions`\n",
    "- CLass label column (y): `Total Interactions`\n",
    "\n",
    "#### 5. Build a 3-layer neural network with `relu` as the 2 hidden layers' activation function and `sigmoid` as the final layer's activation function. \n",
    "- Ensure your `model` is `Sequential`.\n",
    "- Use the same `adam` optimizer and `mean_squared_error` as the loss function. \n",
    "- `epochs`=150, `batch_size`=10\n",
    "- since the class label is continuous, we use `metrics.MeanSquaredError()` as the metric (`from keras import metrics`) to measure the performance of our classifier captured as variable `mse` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b373417",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f6217b712a0922f11299ca4d760f26e",
     "grade": false,
     "grade_id": "keras",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Please run this cell to install keras\n",
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95db92f6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe21c30cdf8a9fe49c2073c58a506a39",
     "grade": false,
     "grade_id": "q2-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Justin\\anaconda3\\envs\\MGMT-4190\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0020866014529019594"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import metrics\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# 1\n",
    "df_sub4 = df[['Page total likes', 'Type', 'Category', 'Post Month', 'Post Weekday', 'Post Hour', 'Paid', 'Total Interactions']]\n",
    "\n",
    "# 2\n",
    "df_OHE = pd.get_dummies(df_sub4, columns=['Type', 'Category', 'Post Month', 'Post Weekday', 'Post Hour'])\n",
    "\n",
    "# 3\n",
    "scaler = MinMaxScaler()\n",
    "df_OHE[['Page total likes', 'Total Interactions']] = scaler.fit_transform(df_OHE[['Page total likes', 'Total Interactions']])\n",
    "\n",
    "# 4\n",
    "X = df_OHE.drop('Total Interactions', axis=1)\n",
    "y = df_OHE['Total Interactions']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 5\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[metrics.MeanSquaredError()])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10, verbose=0)\n",
    "mse = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "mse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25cf88e7-c313-4170-b047-843eed9b490f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58ab688dbb225a83375ca51c4bfc4eaa",
     "grade": true,
     "grade_id": "t2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#check for variable names\n",
    "assert 'df_OHE' in globals()\n",
    "assert 'X_train' in globals()\n",
    "assert 'y_test' in globals()\n",
    "assert 'mse' in globals()\n",
    "assert 'model' in globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97ab82",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97441978b4adb45c37027af9e8fa7a0f",
     "grade": true,
     "grade_id": "5",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-5 (8 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ba034fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab9f2b8daf835a69112f08bec3f7dba6",
     "grade": true,
     "grade_id": "6",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-6 (8 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL\n",
    "assert len(X_train)==346\n",
    "assert len(y_test)==149\n",
    "assert mse<0.005\n",
    "assert len(model.weights)==6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca96cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MGMT-4190",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
