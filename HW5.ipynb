{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3305cb54-7873-4eaf-82e7-46ba5d1a4539",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07bdb6ec1c0025aaeeb9f7775063d34f",
     "grade": false,
     "grade_id": "Desc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Assignment-5\n",
    "##### Total number of points: 45\n",
    "#### Due date: 11/7/2024 11:59 PM\n",
    "\n",
    "Before you submit this homework, make sure everything runs as expected. First, restart the kernel (in the menu, select Kernel → Restart) and then run all cells (in the menubar, select Cell → Run All). You can discuss with others regarding the homework but all work must be your own.\n",
    "\n",
    "Steps to evaluate your solutions:\n",
    "\n",
    "Step-1: Try on Colab or Anaconda (Windows: https://docs.anaconda.com/anaconda/install/windows/ ; Mac:https://docs.anaconda.com/anaconda/install/mac-os/ ; Linux: https://docs.anaconda.com/anaconda/install/linux/)\n",
    "\n",
    "Step-2: Open the Jupyter Notebook by first launching the anaconda software console\n",
    "\n",
    "Step-3: Open the homework's .ipynb file and write your solutions at the appropriate location \"# YOUR CODE HERE\"\n",
    "\n",
    "Step-4: You can restart the kernel and click run all (in the menubar, select Cell → Run All) on the center-right on the top of this window.\n",
    "\n",
    "Step-5: Now go to \"File\" then click on \"Download as\" then click on \"Notebook (.ipynb)\" Please DO NOT change the file name and just keep it as \".ipynb\"\n",
    "\n",
    "Step-6: Go to lms.rpi.edu and upload your homework at the appropriate link to submit this homework.\n",
    "\n",
    "\n",
    "#### Please note that for any question in this assignment you will receive points ONLY if your solution passes all the test cases including hidden testcases as well. So please make sure you try to think all possible scenarios before submitting your answers.  \n",
    "- Note that hidden tests are present to ensure you are not hardcoding.\n",
    "- Failure to use proper letter casing for variable names will lead to loss of points. \n",
    "- If caught cheating: \n",
    "    - you will receive a score of 0 for the 1st violation. \n",
    "    - for repeated incidents, you will receive an automatic 'F' grade and will be reported to the dean of Lally School of Management.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca70a8-9a2d-4277-bbb2-daeb2b6aaacc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5bdaadc14906c211504197ce34e2bf6",
     "grade": false,
     "grade_id": "Q1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q1 [10 points]. We have loaded the wine dataset (from sklearn.datasets) -- use a dataframe 'df' to perform the following tasks:\n",
    "\n",
    "###### 1. **Without using train_test_split() function** \n",
    "- Use the last 78 rows (i.e., index 100,101,....177) for training. Where, the corresponding features are loaded as `train_X` and corresponding labels as `train_y`.\n",
    "- Use the remaining rows as testing data -- `test_X` and `test_y` for the features and labels respectively.\n",
    "- Note that `train_X`, `train_y`,  `test_X` and `test_y` are dataframes.\n",
    "- Fit a logistic regression with solver=`newton-cg`, C=1e5, multi_class=`multinomial`; then use it for predicting testing data as shown in the lecture notebook. \n",
    "\n",
    "###### 2. Measure the accuracy `acc_split1` using the predicted labels with groundtruth test labels `test_y`.\n",
    "- Round the `acc_split1` to 2 values after the decimal point. \n",
    "- Hint -- Check out the libraries give\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c447a68-e258-4eec-a62d-ba42851bfe4b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e29e78314c133aa27c7dfc894c1e5a67",
     "grade": false,
     "grade_id": "Q1-Sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Justin\\anaconda3\\envs\\MGMT-4190\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.36,\n",
       " Index(['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
       "        'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
       "        'proanthocyanins', 'color_intensity', 'hue',\n",
       "        'od280/od315_of_diluted_wines', 'proline'],\n",
       "       dtype='object'),\n",
       " (78,),\n",
       " (100, 13),\n",
       " (100,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Load the dataset without class labels and save it as a dataframe\n",
    "wine = load_wine()\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "#class label -- wine.target\n",
    "#print(len(df))\n",
    "\n",
    "train_X = pd.DataFrame()\n",
    "train_y = pd.DataFrame()\n",
    "test_X = pd.DataFrame()\n",
    "test_y = pd.DataFrame()\n",
    "\n",
    "acc_split1=0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "X, y = load_wine(as_frame=True, return_X_y=True)\n",
    "train_X = X[100:]\n",
    "train_y = y[100:]\n",
    "test_X = X[:100]\n",
    "test_y = y[:100]\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = LogisticRegression(solver='newton-cg', C=1e5, multi_class='multinomial')\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# Predict the testing data\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "# Measure the accuracy\n",
    "acc_split1 = round(accuracy_score(test_y, pred_y), 2)\n",
    "acc_split1, train_X.columns, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c5e705-b7c3-47d7-bce9-9abe991f0b51",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22a5d3aa91e306e17b5f98a195cf2aca",
     "grade": true,
     "grade_id": "c1",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#check for variable names\n",
    "assert 'train_X' in globals()\n",
    "assert 'train_y' in globals()\n",
    "assert 'test_X' in globals()\n",
    "assert 'test_y' in globals()\n",
    "assert 'acc_split1' in globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d4120c-16d1-4105-b7ac-3e9432a7c627",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da8c880d50866d3d6a77a3c9ad006e43",
     "grade": true,
     "grade_id": "1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-1 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL\n",
    "assert len(train_X)==78\n",
    "assert len(test_y)==100\n",
    "assert acc_split1==0.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b5d724-f8c1-446d-9189-86e8d0671ec4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccc8173850df02ca7276a1e440bb8871",
     "grade": true,
     "grade_id": "2",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-2 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c15b9-12cd-4ca6-b4d0-1de77c8761b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24b84f288d116a5c1c691c75a76b40dd",
     "grade": false,
     "grade_id": "Q2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q2 [10 points].  Repeat the above exercise (Q1) but with different training and testing splits using the `wine` dataset.\n",
    "\n",
    "###### 1. **Without using train_test_split() function** \n",
    "- Use the first 100 rows (i.e., index 0,1,....99) as training data -- `train_X` and `train_y` for the features and labels respectively.\n",
    "- Use the last 78 rows (i.e., index 100,101,....177) for testing. Where, the corresponding features are loaded as `test_X` and corresponding labels as `test_y`.\n",
    "- Note that `train_X`, `train_y`,  `test_X` and `test_y` are dataframes.\n",
    "- Fit a logistic regression with solver=`newton-cg`, C=1e5, multi_class=`multinomial`; then use it for predicting testing data as shown in the lecture notebook. \n",
    "\n",
    "###### 2. Measure the accuracy `acc_split2` using the predicted labels with groundtruth test labels `test_y`.\n",
    "- Round the `acc_split2` to 2 values after the decimal point. \n",
    "- Hint -- Check out the libraries give\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315085c0-5b97-4280-a549-6dfb37aa63be",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d590a780662fc3681af24e17fb3ba062",
     "grade": false,
     "grade_id": "Q2-Sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Justin\\anaconda3\\envs\\MGMT-4190\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.35,\n",
       " Index(['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
       "        'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
       "        'proanthocyanins', 'color_intensity', 'hue',\n",
       "        'od280/od315_of_diluted_wines', 'proline'],\n",
       "       dtype='object'),\n",
       " (100,),\n",
       " (78, 13),\n",
       " (78,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Load the dataset without class labels and save it as a dataframe\n",
    "wine = load_wine()\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "#class label -- wine.target\n",
    "\n",
    "train_X = pd.DataFrame()\n",
    "train_y = pd.DataFrame()\n",
    "test_X = pd.DataFrame()\n",
    "test_y = pd.DataFrame()\n",
    "\n",
    "acc_split2=0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "X, y = load_wine(as_frame=True, return_X_y=True)\n",
    "train_X = X[:100]\n",
    "train_y = y[:100]\n",
    "test_X = X[100:]\n",
    "test_y = y[100:]\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = LogisticRegression(solver='newton-cg', C=1e5, multi_class='multinomial')\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# Predict the testing data\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "# Measure the accuracy\n",
    "acc_split2 = round(accuracy_score(test_y, pred_y), 2)\n",
    "acc_split2, train_X.columns, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e7edcf9-35d1-4e78-a6be-ba4c0cebe352",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c589b0fd015f22d8decb9b77468b1dd",
     "grade": true,
     "grade_id": "c2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#check for variable names\n",
    "assert 'train_X' in globals()\n",
    "assert 'train_y' in globals()\n",
    "assert 'test_X' in globals()\n",
    "assert 'test_y' in globals()\n",
    "assert 'acc_split2' in globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d6c1c20-eecb-4cd0-b110-4169a7a565d5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83404c22a77f74dd891d6dd2fda9dc10",
     "grade": true,
     "grade_id": "3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-3 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL\n",
    "assert len(train_X)==100\n",
    "assert len(test_y)==78\n",
    "assert acc_split2==0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7e50012-3b48-4367-9413-1860ee92c091",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "778910a25e0c056786e8cd6de63fe219",
     "grade": true,
     "grade_id": "4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-4 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd6ba2-f183-4912-8a2a-ede32af8b73c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "553b3520e57de5af95c9849966c4bd93",
     "grade": false,
     "grade_id": "Q3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3 [10 points]. Please refer to the data table shown in Lecture-14 (slide-33). \n",
    "- Compute entropy after splitting the original data using the attribute `credit_rating` and save it as variable `entropy_cr`. \n",
    "- Compute the information gain (use the variable `info_gain`) if we split the original data using `credit_rating` this information gain computation requires you to compute the total entropy before splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "041ca3e4-2254-47dd-b6c7-bc817b539871",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85121f304629de64530c23952e718804",
     "grade": false,
     "grade_id": "Q3-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.8921589282623617), np.float64(0.04812703040826949))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "entropy_cr=-1 #this has to be updated using your computations\n",
    "info_gain=-1 #this has to be updated\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Define the dataset\n",
    "data = {\n",
    "    'age': ['<=30', '<=30', '31...40', '>40', '>40', '>40', '31...40', '<=30', '<=30', '>40', '<=30', '31...40', '31...40', '>40'],\n",
    "    'income': ['high', 'high', 'high', 'medium', 'low', 'low', 'low', 'medium', 'low', 'medium', 'medium', 'medium', 'high', 'medium'],\n",
    "    'student': ['no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no'],\n",
    "    'credit_rating': ['fair', 'excellent', 'fair', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'excellent'],\n",
    "    'buys_computer': ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "\n",
    "# Function to calculate entropy\n",
    "def entropy(labels):\n",
    "  value, counts = np.unique(labels, return_counts=True)\n",
    "  probs = counts / len(labels)\n",
    "  return -np.sum(probs * np.log2(probs))\n",
    "\n",
    "# Calculate total entropy before splitting\n",
    "total_entropy = entropy(df['buys_computer'])\n",
    "\n",
    "# Calculate entropy after splitting by credit_rating\n",
    "entropy_cr = 0\n",
    "for value in df['credit_rating'].unique():\n",
    "  subset = df[df['credit_rating'] == value]\n",
    "  entropy_cr += (len(subset) / len(df)) * entropy(subset['buys_computer'])\n",
    "\n",
    "# Calculate information gain\n",
    "info_gain = total_entropy - entropy_cr\n",
    "\n",
    "entropy_cr, info_gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d393bb17-c891-40c5-80a9-e8f3a5a789f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee2af3385a56fe6a3cdeed197d62970f",
     "grade": true,
     "grade_id": "c3",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#check for variable names\n",
    "assert 'entropy_cr' in globals()\n",
    "assert 'info_gain' in globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "032f0870-b758-4629-8d0e-492ff3f97492",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "763370645c2b10f28c131bdae0ebcdaa",
     "grade": true,
     "grade_id": "5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-5 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL\n",
    "assert round(entropy_cr, 2)==0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8cc666b-481a-43ae-b156-e166ef76e07c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8532d98816f7bdcdb31c75fa500af263",
     "grade": true,
     "grade_id": "6",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-6 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7d4e21-de26-4c8b-9f4c-a27962f2436b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "652645d8e99111fb4a503258b9c6416b",
     "grade": false,
     "grade_id": "Q4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q4 [10 points]. Decision Tree Classifier  \n",
    "\n",
    "###### 1. **Using train_test_split() function** \n",
    "- Create `train_X`, `train_y`,  `test_X` and `test_y` as dataframes corresponding to the training and testing datasets using `80:20` ratio for training and testing data split and with a `random_state` as `5`.\n",
    "- Fit a Decision Tree Classifier `dt` with criterion as `entropy` and a `random_state` as `10` using training data; then use it for predicting testing data. \n",
    "\n",
    "###### 2. Measure the accuracy `acc_split3` using the predicted labels with groundtruth test labels `test_y`.\n",
    "- Round the `acc_split3` to 2 values after the decimal point. \n",
    "- Hint -- Check out the libraries give\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83b0bbb2-ed2f-45a1-b4e7-74e6489fb9a6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb717d8608f45e80731f2dfbf4f2a406",
     "grade": false,
     "grade_id": "Q4-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Load the dataset without class labels and save it as a dataframe\n",
    "wine = load_wine()\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "#class label -- wine.target\n",
    "\n",
    "train_X = pd.DataFrame()\n",
    "train_y = pd.DataFrame()\n",
    "test_X = pd.DataFrame()\n",
    "test_y = pd.DataFrame()\n",
    "\n",
    "acc_split3 = 0\n",
    "# YOUR CODE HERE\n",
    "train_X, test_X, train_y, test_y = train_test_split(df, wine.target, test_size=0.2, random_state=5)\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='entropy', random_state=10)\n",
    "dt.fit(train_X, train_y)\n",
    "\n",
    "# Predict the testing data\n",
    "pred_y = dt.predict(test_X)\n",
    "\n",
    "# Measure the accuracy\n",
    "acc_split3 = round(accuracy_score(test_y, pred_y), 2)\n",
    "acc_split3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f41d758c-ed8f-41c1-ac01-5bb32344eff3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34caad1c4b9fbe6afe107e0d2c952b9e",
     "grade": true,
     "grade_id": "c4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#check for variable names\n",
    "assert 'train_X' in globals()\n",
    "assert 'train_y' in globals()\n",
    "assert 'test_X' in globals()\n",
    "assert 'test_y' in globals()\n",
    "assert 'acc_split3' in globals()\n",
    "assert 'dt' in globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9f867a4-662e-4b88-b848-f7a7357d9287",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21edd527ce7813135b11f2813307cd4d",
     "grade": true,
     "grade_id": "7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-7 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL\n",
    "assert len(train_X)==142\n",
    "assert len(test_y)==36\n",
    "assert dt.criterion=='entropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5374f84e-edb4-4123-94d4-2b0b728ae65c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce56bcc3565c5affb015b09e11ca4809",
     "grade": true,
     "grade_id": "8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-8 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c9e2ac-c20c-479a-8896-2010d1d963ab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3c7b4516f2f334cf0c41ad1655c3a6c",
     "grade": false,
     "grade_id": "Q5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q5 [5 points]. TF-IDF. \n",
    "- Given a corpus with three documents `D1`, `D2`, and `D3`: \n",
    "<ul>\n",
    "<li>D1: The quick red fox jumps over the lazy dog.</li>\n",
    "<li>D2: A quick red fox jumps over the lazy dog.</li>\n",
    "<li>D3: The lazy dog watches as a quick red fox jumps over it.</li>\n",
    "</ul>\n",
    "- Convert all the documents into lowercase. \n",
    "- Remove all non-alphanumeric characters in all these documents.\n",
    "- Then perform TF-IDF vectorization of these documents and save them as `TD1`, `TD2`, and `TD3` respectively.\n",
    "- Compute the cosine similarity values and find the two documents with the closest similarity. Save this as a list variable `sim_docs` that contains the transformed names of these two documents to receive full points. For instance, if `D3` and `D1` are the most similar, `sim_docs` will be `['TD3', 'TD1']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddda4780-57b6-4abe-ae1d-d1f48220acd0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71c076f489bc02fcb7c38d070a52ca7a",
     "grade": false,
     "grade_id": "Q5-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.95940322 0.66602258]\n",
      " [0.95940322 1.         0.69420507]\n",
      " [0.66602258 0.69420507 1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['TD1', 'TD2']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the two most similar documents using TF-IDF vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim_docs=[]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "D1 = 'The quick red fox jumps over the lazy dog.'\n",
    "D2 = 'A quick red fox jumps over the lazy dog.'\n",
    "D3 = 'The lazy dog watches as a quick red fox jumps over it.'\n",
    "D1 = D1.lower().replace('.','')\n",
    "D2 = D2.lower().replace('.','')\n",
    "D3 = D3.lower().replace('.','')\n",
    "tfidf_matrix = TfidfVectorizer().fit_transform([D1, D2, D3])\n",
    "TD1, TD2, TD3 = tfidf_matrix.toarray()\n",
    "# print(tfidf_matrix)\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "print(cosine_sim)\n",
    "sim_index = np.unravel_index(np.argmax(cosine_sim - np.eye(cosine_sim.shape[0])), cosine_sim.shape)\n",
    "sim_docs = [f'TD{sim_index[0] + 1}', f'TD{sim_index[1] + 1}']\n",
    "sim_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04f44f20-c2b8-4cbd-a7bf-7dedbfc44ec1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0648bc485ba94303fe5f9081659e1e4b",
     "grade": true,
     "grade_id": "c5",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#check for variable names\n",
    "assert 'D1' in globals()\n",
    "assert 'D2' in globals()\n",
    "assert 'D3' in globals()\n",
    "assert 'sim_docs' in globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f713851-eb4b-4598-aa6f-35b6842cb5a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bdcb33b7eb5be62ece9c54bc80ebfa2",
     "grade": true,
     "grade_id": "9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Test cell-9 (5 points)\n",
    "#DO NOT MODIFY/DELETE THIS CELL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MGMT-4190",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
